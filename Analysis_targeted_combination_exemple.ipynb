{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from itertools import combinations\n","import multiprocessing\n","from multiprocessing import Manager\n","import csv\n","import time\n","\n","# Start time tracking\n","startTime = time.time()\n","\n","# Load target list\n","target_list = pd.read_csv('target_taxo_list.csv', sep=\"\\t\")\n","target_list = list(target_list.iloc[:, 0])\n","\n","# List of donors to process\n","donor_list = ['Pr1', 'Pr2', 'Pr3', 'Pr5', 'Pr6', 'Pr7']\n","\n","# Function to generate all possible media combinations\n","def media_combinations_list_generation(list_of_conditions, min_comb, max_comb): \n","    media_comb_list = []\n","    for n in range(min_comb, max_comb):\n","        media_comb = list(combinations(list_of_conditions, n))\n","        media_comb_list.append(media_comb)\n","    # Flatten the list of combinations\n","    media_comb_list = [item for sublist in media_comb_list for item in sublist]\n","    return media_comb_list\n","\n","# Function to compute metrics for each media combination\n","def media_compute(mix):\n","    row = []\n","    \n","    # Filter target taxo benchmark for the given media combination\n","    marker_for_mix = target_taxo_benchmark_filtered[list(mix)]\n","    \n","    # Remove rows that contain a 0 (absent OTUs)\n","    marker_for_mix = marker_for_mix[~(marker_for_mix == 0).any(1)]\n","    \n","    # Calculate total number of OTUs in the combination\n","    total_OTU = len(marker_for_mix)\n","    if total_OTU > 0:\n","        # Calculate mean relative abundance (RA) per OTU\n","        marker_for_mix['Mean_RA_OTU'] = marker_for_mix.mean(axis=1, numeric_only=True).round(3)\n","        marker_for_mix.sort_values(by='Mean_RA_OTU', inplace=True, ascending=False)\n","        \n","        # Get the target mean RA\n","        target_mean_RA = marker_for_mix.loc[target, 'Mean_RA_OTU']\n","        sum_mean_RA = marker_for_mix['Mean_RA_OTU'].sum()\n","        \n","        # Calculate the ratio of target RA over total RA\n","        ratio_target_total_mean_RA_in_percent = (target_mean_RA / sum_mean_RA) * 100\n","        \n","        # Get the top 3 OTUs if available\n","        if len(marker_for_mix) >= 3:\n","            top = {\n","                'Top1': marker_for_mix.index[0], 'Top1_RA': marker_for_mix.iloc[0, -1],\n","                'Top2': marker_for_mix.index[1], 'Top2_RA': marker_for_mix.iloc[1, -1],\n","                'Top3': marker_for_mix.index[2], 'Top3_RA': marker_for_mix.iloc[2, -1]\n","            }\n","        else:\n","            top = 'Less than 3 OTUs detected in combos'\n","        \n","        # Append the computed metrics to the row\n","        row = [total_OTU, target_mean_RA, ratio_target_total_mean_RA_in_percent, [str(','.join(str(e) for e in mix))], top]\n","        record.append(row)\n","\n","# Main loop to process each donor and target\n","for donor in donor_list:\n","    # Load the target taxo benchmark dataset for the donor\n","    target_taxo_benchmark = pd.read_csv(f'target_taxo_benchmark_df_{donor}.csv', sep=\"\\t\")\n","    \n","    for target in target_list:\n","        # Filter the dataset for the target OTU\n","        species_to_target = target_taxo_benchmark[target_taxo_benchmark['OTU'] == target]\n","        record = Manager().list()\n","        target_name_reformated = target.replace('/', '-')\n","        \n","        # Create CSV file to store output combinations\n","        csv_file = open(f\"output_{target_name_reformated}_{donor}_combinations.csv\", 'w')\n","        csv_writer = csv.writer(csv_file, delimiter=\"\\t\") \n","        \n","        # Check if the dataset is not empty and has enough columns\n","        if not ((species_to_target.empty) or (len(species_to_target.columns) <= 2)):\n","            # Filter columns with non-zero values\n","            species_to_target = species_to_target.loc[:, (species_to_target != 0).any(0)].dropna(axis=1)\n","            conditions_to_combo = species_to_target.columns\n","            \n","            # Filter the target taxo benchmark by selected conditions\n","            target_taxo_benchmark_filtered = target_taxo_benchmark[conditions_to_combo]\n","            target_taxo_benchmark_filtered.set_index('OTU', inplace=True)\n","            \n","            # Generate media combinations (up to 6 conditions)\n","            media_combinations_list = media_combinations_list_generation(conditions_to_combo[1:], 1, 6)\n","            \n","            # Use multiprocessing to process combinations in parallel\n","            if __name__ == '__main__':\n","                pool = multiprocessing.Pool(12)\n","                pool.map(media_compute, media_combinations_list)\n","        \n","        # Write the results to the CSV file\n","        csv_writer.writerows(record)\n","        csv_file.close()\n","        \n","        # Print execution time for each target\n","        executionTime = (time.time() - startTime)\n","        print(f'Execution time in seconds: {executionTime} for target {target}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import gc\n","import time\n","import os\n","\n","# Start time tracking\n","startTime = time.time()\n","\n","# List of donors\n","donor_list = ['Pr1', 'Pr2', 'Pr3', 'Pr5', 'Pr6', 'Pr7']\n","\n","# Load metadata\n","metadata_df = pd.read_csv(\"metadata_benchmark_2.csv\", usecols=['Sample_ID', 'Modification'], sep=\"\\t\")\n","modification = metadata_df.set_index('Sample_ID')['Modification'].to_dict()\n","\n","# Load taxonomic data\n","taxo_df_melted = pd.read_csv(\"taxo_RA_v2_df_melted.csv\", sep=\"\\t\", index_col=[0])\n","target_taxo_level_df = taxo_df_melted[taxo_df_melted['Count'] != 0]\n","target_taxo_level_df = target_taxo_level_df[['Phylum', 'Family', 'Genus', 'OTU']].drop_duplicates().reset_index(drop=True)\n","target_taxo_level_df.columns = ['Phylum', 'Family', 'Genus', 'Target']\n","\n","# Initialize dataframe to hold all combinations\n","all_donor_set = pd.DataFrame()\n","\n","# Iterate over each donor\n","for chosen_donor in donor_list:\n","    target_benchmark = pd.read_csv(f'target_taxo_benchmark_df_{chosen_donor}.csv', sep=\"\\t\")\n","    target_list = target_benchmark['OTU'].unique()\n","    target_list = [t.replace('/', '-') for t in target_list]\n","    \n","    # Process each target\n","    for target in target_list:\n","        dataset = os.path.isfile(f'output_{target}_{chosen_donor}_combinations.csv')\n","        \n","        if dataset:\n","            filesize = os.path.getsize(f'output_{target}_{chosen_donor}_combinations.csv')\n","            \n","            if filesize != 0:\n","                # Load combinations data for the target\n","                combinations_df = pd.read_csv(f'output_{target}_{chosen_donor}_combinations.csv', sep='\\t',\n","                                              names=['Total OTUs in combo', 'Target mean RA', 'Ratio Target over Total mean RA percentage', \n","                                                     'Media combination', 'Top 3 OTUs in the combo'])\n","                \n","                # Sort based on ranking criteria\n","                combinations_df.sort_values(by=['Ratio Target over Total mean RA percentage', 'Total OTUs in combo', 'Target mean RA'], ascending=False, inplace=True)\n","                combinations_df = combinations_df.head(150)\n","                \n","                # Clean up media combinations\n","                combinations_df['Media combination'] = combinations_df['Media combination'].str.replace(\"'\", '').str.replace(\"[\", '').str.replace(\"]\", '')\n","                combinations_df['Media combination'] = combinations_df['Media combination'].apply(lambda x: set(x.strip(\"[]\").split(\",\")))\n","                combinations_df['Number of media in combo'] = combinations_df['Media combination'].str.len()\n","                combinations_df['Target'] = target\n","                combinations_df['Donor'] = chosen_donor\n","                \n","                # Prepare dataframe for merging\n","                combin_name = pd.DataFrame(combinations_df['Media combination'].values.tolist()).rename(columns=lambda x: f'Media {x + 1}').fillna('None')\n","                combinations_df = pd.merge(left=combinations_df, right=combin_name, left_index=True, right_index=True)\n","                combinations_df.drop('Media combination', inplace=True, axis=1)\n","                \n","                # Apply filtering rules\n","                result_curated_ph = combin_name.copy()\n","                result_curated_temp = combin_name.copy()\n","                result_curated_ph.fillna('None', inplace=True)\n","                \n","                result_curated_ph_counts = result_curated_ph.apply(lambda x: x.str.count(\"pH\")).sum(axis=1)\n","                result_curated_temp_counts = result_curated_temp.apply(lambda x: x.str.count(\"Temp\")).sum(axis=1)\n","                \n","                # Filter combinations with certain conditions\n","                filtered_combinations = combinations_df[(result_curated_ph_counts < 2) & (result_curated_temp_counts < 2)].head(100)\n","                filtered_combinations.to_csv(f'output_taxo_{target}_{chosen_donor}_combinations_top100.csv', sep='\\t', index=False)\n","                \n","                # Clean memory\n","                del combinations_df\n","                gc.collect()\n","\n","# After processing, combine all results into one dataset\n","all_donor_set.to_csv('output_taxo_all_compound_combinations_curated_all_donors.csv', sep='\\t', index=False)\n","\n","# Completion time\n","executionTime = (time.time() - startTime)\n","print('Execution time in seconds: ' + str(executionTime))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import plotly.express as px\n","\n","# Load processed data for Collinsella aerofaciens\n","species_level_all_donor_all_combo = pd.read_csv('output_taxo_all_compound_combinations_curated_all_donors.csv', sep='\\t')\n","\n","# Filter data for Collinsella aerofaciens\n","selected_target = 'Collinsella aerofaciens'\n","filtered_df = species_level_all_donor_all_combo[species_level_all_donor_all_combo['Target'] == selected_target]\n","\n","# Plotting the results\n","fig = px.scatter(filtered_df, y='Total OTUs in combo', x='Target mean RA', color='Donor', \n","                 size='Number of unique media in combo',\n","                 hover_data=['Target', 'Donor', 'Total OTUs in combo', 'Target mean RA',\n","                             'Ratio Target over Total mean RA percentage', \n","                             'Media 1', 'Media 2', 'Media 3', 'Media 4', \n","                             'Media 5', 'Media 6', 'Media 7', 'Media 8',\n","                             'Number of unique media in combo'])\n","\n","fig.update_layout(title={'text': f'Total OTU recovery and relative abundance for {selected_target} per media combination',\n","                         'y': 0.99, 'x': 0.5, 'xanchor': 'center', 'yanchor': 'top'}, \n","                  title_font_size=20)\n","\n","fig.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import base64\n","import dash\n","from dash.dependencies import Input, Output\n","import dash_core_components as dcc\n","import dash_html_components as html\n","import plotly.express as px\n","\n","# Load the processed dataset for all combinations across all donors\n","species_level_all_donor_all_combo = pd.read_csv('output_taxo_all_compound_combinations_curated_all_donors.csv', sep='\\t')\n","\n","# Calculate the number of media used in each combination\n","species_level_all_donor_all_combo = species_level_all_donor_all_combo.fillna('None')\n","empty_media_cell = species_level_all_donor_all_combo.apply(lambda x: (x == 'None').sum(), axis='columns')\n","species_level_all_donor_all_combo['Number of unique media in combo'] = 8 - empty_media_cell\n","species_level_all_donor_all_combo = species_level_all_donor_all_combo[species_level_all_donor_all_combo['Number of unique media in combo'] > 1]\n","\n","# List all available targets in the dataset\n","list_target = species_level_all_donor_all_combo['Target'].sort_values().unique()\n","\n","# Dash app setup\n","app = dash.Dash(__name__)\n","app.config.suppress_callback_exceptions = True\n","\n","# App layout\n","app.layout = html.Div(children=[\n","    html.H1(\"Analysis app for selecting targeted enrichment combinations\"),\n","    \n","    dcc.Dropdown(id='dropdown_target_select', \n","                 options=[{'label': i, 'value': i} for i in list_target],\n","                 value='Collinsella aerofaciens', multi=False, \n","                 placeholder='Filter by target'),\n","\n","    html.Div([\n","        html.Div(id='graph'),\n","        html.Div(id='network-heatmap'),\n","    ], className=\"row\")   \n","])\n","\n","@app.callback([Output('graph', 'children'), Output('network-heatmap', 'children')],\n","              [Input('dropdown_target_select', 'value')])\n","def select_graph(value):\n","    selected_target_all_compound_combo = species_level_all_donor_all_combo[species_level_all_donor_all_combo['Target'] == value]\n","    \n","    fig = px.scatter(selected_target_all_compound_combo, \n","                     y='Total OTUs in combo', \n","                     x='Target mean RA', \n","                     color='Donor',\n","                     size='Number of unique media in combo', \n","                     hover_data=['Target', 'Donor', 'Total OTUs in combo', 'Target mean RA',\n","                                 'Ratio Target over Total mean RA percentage', \n","                                 'Media 1', 'Media 2', 'Media 3', 'Media 4', \n","                                 'Media 5', 'Media 6', 'Media 7', 'Media 8',\n","                                 'Number of unique media in combo'],\n","                     template='plotly_white')\n","    \n","    fig.update_layout(title={'text': f'Total OTU recovery and relative abundance (%) for {value} per media combination',\n","                             'y': .99, 'x': 0.5, 'xanchor': 'center', 'yanchor': 'top'}, \n","                      title_font_size=30)\n","    fig.update_layout(plot_bgcolor='rgba(0, 0, 0, 0)', \n","                      paper_bgcolor='rgba(0, 0, 0, 0)', \n","                      autosize=False, width=1500, height=400, \n","                      margin=dict(l=20, r=20, b=20, t=60, pad=4))\n","    \n","    fig.update_layout(legend=dict(title='Sample donor:', orientation=\"h\",\n","                                  yanchor=\"bottom\", y=0.99, \n","                                  xanchor=\"left\", x=0.1))\n","\n","    encoded_image = base64.b64encode(open(f'{value} - Network graph and heatmap of the mean relative abundance for {value} markers in most prevalent media.png', 'rb').read())\n","    source = 'data:image/png;base64,{}'.format(encoded_image.decode())\n","\n","    return [dcc.Graph(figure=fig, style={'display': 'inline-block', 'vertical-align': 'middle'}),\n","            html.Img(src=source, style={'height': '70%', 'width': '50%', 'display': 'inline-block',\n","                                        'vertical-align': 'middle', 'horizontal-align': 'right', \n","                                        'margin-left': '100px'})]\n","\n","if __name__ == \"__main__\":\n","    app.run_server(debug=False)\n"]}],"metadata":{"interpreter":{"hash":"487d5d63676aa77116cea4922fd2d9cd065fc9047ce32247100a72cb302f2685"},"kernelspec":{"display_name":"Python 3.8.12 ('data-analysis')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
